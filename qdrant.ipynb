{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Vscode_projects\\Intro_to_LLM\\habr_rag_bot\\.habr_rag_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# from datasets import load_dataset\n",
    "\n",
    "import os\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from qdrant_client import QdrantClient\n",
    "from langchain.schema import Document\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = load_dataset(\"IlyaGusev/habr\", trust_remote_code=True)\n",
    "# ds.save_to_disk(\"D:\\Vscode_projects\\Intro_to_LLM\\data\\habr_data\")\n",
    "# df = ds[\"train\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10 = pd.read_csv('../data/habr_10_percent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>language</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text_markdown</th>\n",
       "      <th>text_html</th>\n",
       "      <th>author</th>\n",
       "      <th>original_author</th>\n",
       "      <th>original_url</th>\n",
       "      <th>lead_html</th>\n",
       "      <th>lead_markdown</th>\n",
       "      <th>type</th>\n",
       "      <th>time_published</th>\n",
       "      <th>statistics</th>\n",
       "      <th>labels</th>\n",
       "      <th>hubs</th>\n",
       "      <th>flows</th>\n",
       "      <th>tags</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>format</th>\n",
       "      <th>complexity</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28550</th>\n",
       "      <td>193378</td>\n",
       "      <td>ru</td>\n",
       "      <td>https://habr.com/ru/post/193378/</td>\n",
       "      <td>Установка и настройка TeamSpeak 3 сервера на VDS</td>\n",
       "      <td>В данной статье речь пойдет об установке серве...</td>\n",
       "      <td>&lt;div xmlns=\"http://www.w3.org/1999/xhtml\"&gt;В да...</td>\n",
       "      <td>Dmitry Kolesnikov (mittus)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>В данной статье речь пойдет об &lt;b&gt;установке се...</td>\n",
       "      <td>В данной статье речь пойдет об установке серве...</td>\n",
       "      <td>article</td>\n",
       "      <td>1378909610</td>\n",
       "      <td>{'commentsCount': 17, 'favoritesCount': 114, '...</td>\n",
       "      <td>['sandbox']</td>\n",
       "      <td>['s_admin']</td>\n",
       "      <td>['admin']</td>\n",
       "      <td>['teamspeak' 'debian' 'ubuntu' 'ts3']</td>\n",
       "      <td>3.0</td>\n",
       "      <td>tutorial</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'id': array([6715744, 6715764, 6715776, 67164...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13904</th>\n",
       "      <td>166575</td>\n",
       "      <td>ru</td>\n",
       "      <td>https://habr.com/ru/post/166575/</td>\n",
       "      <td>Показ масштабируемых изображений</td>\n",
       "      <td>Традиционная работа HTML-страниц с картинками ...</td>\n",
       "      <td>&lt;div xmlns=\"http://www.w3.org/1999/xhtml\"&gt;&lt;a h...</td>\n",
       "      <td>spmbt (spmbt)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"https://habr.com/images/px.gif#%3D%22...</td>\n",
       "      <td>Традиционная работа HTML-страниц с картинками ...</td>\n",
       "      <td>article</td>\n",
       "      <td>1358839525</td>\n",
       "      <td>{'commentsCount': 5, 'favoritesCount': 76, 're...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['webdev' 'javascript']</td>\n",
       "      <td>['develop']</td>\n",
       "      <td>['просмотр изображений' 'HabrAjax']</td>\n",
       "      <td>10.0</td>\n",
       "      <td>tutorial</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'id': array([5753983, 5754433, 5757399, 57575...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3134</th>\n",
       "      <td>160621</td>\n",
       "      <td>ru</td>\n",
       "      <td>https://habr.com/ru/post/160621/</td>\n",
       "      <td>Какого цвета Марс?</td>\n",
       "      <td>Сегодня я возьмусь за тему, которая является у...</td>\n",
       "      <td>&lt;div xmlns=\"http://www.w3.org/1999/xhtml\"&gt;Сего...</td>\n",
       "      <td>Виталий Егоров (Zelenyikot)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Сегодня я возьмусь за тему, которая является у...</td>\n",
       "      <td>Сегодня я возьмусь за тему, которая является у...</td>\n",
       "      <td>article</td>\n",
       "      <td>1354711896</td>\n",
       "      <td>{'commentsCount': 138, 'favoritesCount': 233, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['robot' 'photo']</td>\n",
       "      <td>['popsci']</td>\n",
       "      <td>['Марс' 'марсоходы' 'curiosity' 'nasa']</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'id': array([15694707, 15694709, 15694711, 15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id language                               url  \\\n",
       "28550  193378       ru  https://habr.com/ru/post/193378/   \n",
       "13904  166575       ru  https://habr.com/ru/post/166575/   \n",
       "3134   160621       ru  https://habr.com/ru/post/160621/   \n",
       "\n",
       "                                                  title  \\\n",
       "28550  Установка и настройка TeamSpeak 3 сервера на VDS   \n",
       "13904                  Показ масштабируемых изображений   \n",
       "3134                                 Какого цвета Марс?   \n",
       "\n",
       "                                           text_markdown  \\\n",
       "28550  В данной статье речь пойдет об установке серве...   \n",
       "13904  Традиционная работа HTML-страниц с картинками ...   \n",
       "3134   Сегодня я возьмусь за тему, которая является у...   \n",
       "\n",
       "                                               text_html  \\\n",
       "28550  <div xmlns=\"http://www.w3.org/1999/xhtml\">В да...   \n",
       "13904  <div xmlns=\"http://www.w3.org/1999/xhtml\"><a h...   \n",
       "3134   <div xmlns=\"http://www.w3.org/1999/xhtml\">Сего...   \n",
       "\n",
       "                            author original_author original_url  \\\n",
       "28550   Dmitry Kolesnikov (mittus)             NaN          NaN   \n",
       "13904                spmbt (spmbt)             NaN          NaN   \n",
       "3134   Виталий Егоров (Zelenyikot)             NaN          NaN   \n",
       "\n",
       "                                               lead_html  \\\n",
       "28550  В данной статье речь пойдет об <b>установке се...   \n",
       "13904  <a href=\"https://habr.com/images/px.gif#%3D%22...   \n",
       "3134   Сегодня я возьмусь за тему, которая является у...   \n",
       "\n",
       "                                           lead_markdown     type  \\\n",
       "28550  В данной статье речь пойдет об установке серве...  article   \n",
       "13904  Традиционная работа HTML-страниц с картинками ...  article   \n",
       "3134   Сегодня я возьмусь за тему, которая является у...  article   \n",
       "\n",
       "       time_published                                         statistics  \\\n",
       "28550      1378909610  {'commentsCount': 17, 'favoritesCount': 114, '...   \n",
       "13904      1358839525  {'commentsCount': 5, 'favoritesCount': 76, 're...   \n",
       "3134       1354711896  {'commentsCount': 138, 'favoritesCount': 233, ...   \n",
       "\n",
       "            labels                     hubs        flows  \\\n",
       "28550  ['sandbox']              ['s_admin']    ['admin']   \n",
       "13904           []  ['webdev' 'javascript']  ['develop']   \n",
       "3134            []        ['robot' 'photo']   ['popsci']   \n",
       "\n",
       "                                          tags  reading_time    format  \\\n",
       "28550    ['teamspeak' 'debian' 'ubuntu' 'ts3']           3.0  tutorial   \n",
       "13904      ['просмотр изображений' 'HabrAjax']          10.0  tutorial   \n",
       "3134   ['Марс' 'марсоходы' 'curiosity' 'nasa']           9.0       NaN   \n",
       "\n",
       "      complexity                                           comments  \n",
       "28550        NaN  {'id': array([6715744, 6715764, 6715776, 67164...  \n",
       "13904        NaN  {'id': array([5753983, 5754433, 5757399, 57575...  \n",
       "3134         NaN  {'id': array([15694707, 15694709, 15694711, 15...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df10.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10['text_w_title'] = df10['title'] + \"\\n\" +df10['text_markdown']\n",
    "df10[\"text_w_title\"] = df10[\"text_w_title\"].astype(str)\n",
    "df10[\"url\"] = df10[\"url\"].astype(str)\n",
    "df10[\"title\"] = df10[\"title\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание векторной БД и добавление туда документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "separators=[\n",
    "        \"\\n\\n\",             # Разделение по абзацам\n",
    "        \"\\n\",               # Перенос строки\n",
    "        \"[code]\", \"```\",    # Кодовые блоки\n",
    "        \"####\",             # Заголовки четвертого уровня\n",
    "        \"###\",              # Заголовки третьего уровня\n",
    "        \"##\",               # Заголовки второго уровня\n",
    "        \"#\",                # Заголовки первого уровня\n",
    "        \".\",                # Точки в предложениях\n",
    "        \" \"\n",
    "    ]\n",
    "def create_doc_list(df10, chunk_size=1024, chunk_overlap=128, separators=separators):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, separators=separators,\n",
    "        chunk_overlap=chunk_overlap)\n",
    "    \n",
    "    documents = []\n",
    "    for _, row in df10.iterrows():\n",
    "        chunks = text_splitter.split_text(row[\"text_w_title\"])\n",
    "        for chunk in chunks:\n",
    "            documents.append(Document(\n",
    "                page_content=chunk,\n",
    "                metadata={\"link\": str(row[\"url\"]), \"title\": str(row[\"title\"])}\n",
    "            ))\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs = create_doc_list(df10)\n",
    "# embedder = HuggingFaceEmbeddings(model_name=\"sergeyzh/rubert-tiny-turbo\")\n",
    "# client = QdrantClient(path=\"../data/langchain_qdrant_10percent\")\n",
    "\n",
    "# client.create_collection(\n",
    "#     collection_name=\"embed_collection_10percent\",\n",
    "#     vectors_config=VectorParams(size=312, distance=Distance.COSINE),\n",
    "# )\n",
    "\n",
    "# vector_store = QdrantVectorStore(\n",
    "#     client=client,\n",
    "#     collection_name=\"embed_collection_10percent\",\n",
    "#     embedding=embedder,\n",
    "# )\n",
    "\n",
    "# vector_store.add_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подключение к Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivann\\AppData\\Local\\Temp\\ipykernel_7068\\2378406736.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedder = HuggingFaceEmbeddings(model_name=\"sergeyzh/rubert-tiny-turbo\")\n"
     ]
    }
   ],
   "source": [
    "client = QdrantClient(path=\"../data/langchain_qdrant_10percent\")\n",
    "embedder = HuggingFaceEmbeddings(model_name=\"sergeyzh/rubert-tiny-turbo\")\n",
    "collection_name = \"embed_collection_10percent\"\n",
    "\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=collection_name,\n",
    "    embedding=embedder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование генерации ответов по ретривнуты докуменатам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ранее мы обсуждали гоночные машины. Если у тебя есть какие-то вопросы или ты хочешь продолжить разговор на эту тему, дай знать!'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain import hub\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_name = \"herenickname/t-tech_T-lite-it-1.0:q4_k_m\"\n",
    "\n",
    "# Инициализация модели Ollama через LangChain\n",
    "llm = OllamaLLM(model=model_name, base_url= \"http://localhost:11434\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Vscode_projects\\Intro_to_LLM\\habr_rag_bot\\.habr_rag_env\\Lib\\site-packages\\langsmith\\client.py:261: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n",
      "Processing queries:  33%|███▎      | 1/3 [00:03<00:06,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Что такое FAISS?\n",
      "Документы: Одна из таких производных моделей это FISSA (2020 года), как гибрид из более сложных новых и более старых базовых подходов.\n",
      "Рекомендательные модели, учитывающие последовательность действий, увеличивают точность за счет учета динамики предпочтений. При этом постоянные и глобальные предпочтения недооцениваются. FISSA — это state-of-the-art модель на последовательностях событий с self-attention механизмом, которая балансирует локальные (динамические) предпочтения пользователя и глобальные.\n",
      "Для локальных (динамических) предпочтений берется SASRec, как хорошо зарекомендовавший себя метод. Для учета глобальных предпочтений используется location-based (основанный на позиции в пространстве) attention-слой.\n",
      "Здесь используется implicit feedback: то есть на вход поступает последовательность из L последних объектов с которыми взаимодействовал пользователь. Цель — выдать список рекомендаций, в котором реальный следующий объект взаимодействия будет как можно ближе к началу списка.\n",
      " ---Как и зачем мерить FLOPSы\n",
      " ---### Внутреннее устройство\n",
      "Вся фича держится на двух микросервисах. Первый отвечает за получение изображений, поступающих из новых объявлений, их обработку и дальнейшее помещение в индексы FAISS. Второй же реагирует на запросы от пользователя: берёт фото, прогоняет через EfficientNet-B0 + PCA, ищет похожие эмбеддинги с помощью FAISS и отправляет обратно соответствующие объявления, которые также проходят через постфильтрацию. Примеры работы вы можете видеть на скриншотах ниже.\n",
      "Как видите, вся система неплохо справляется со своей задачей, однако, как говорится, «доверяй, но проверяй», так что рекомендуем вам потестить новую фичу уже самостоятельно в нашем мобильном приложении. К слову: фото удаляется сразу после завершения процессинга. Так что за безопасность личных данных можно не переживать :)\n",
      "### Текущие проблемы + дальнейшие планы\n",
      "Эта фича уже используется в системе рекомендаций Циан.\n",
      " ---хабрахабрить\n",
      "а что если\n",
      "?\n",
      " ---Некоторое замешательство может вызвать и официальная маркировка флюса RMA-223-LF-TF — это можно понять, как «бессвинцовый флюс», что порождает вопрос о возможном содержании свинца во флюсах без суффикса \"TF\". Подозрение устраняется чтением общего описания: \"...designed to meet the requirements of Pb-free alloys\" (разработана для обеспечения требований к пайке бессвинцовыми припоями\"). То есть, это не «бессвинцовый флюс», а «флюс, специально предназначенный для бессвинцовых припоев».\n",
      "Общий MSDS для всех густых флюсов не упоминает о каком-либо содержании свинца, равно как и о возможной канцерогенности или влиянии на репродуктивную функцию. Предупреждения о возможном раздражении кожи и умеренной токсичности при вдыхании совершенно уместны — многие вещества, в том числе и чистая канифоль, при возгонке и сгорании образуют соединения, классифицируемые как «умеренно вредные».\n",
      "Ответ: FAISS (Facebook AI Similarity Search) — это библиотека для эффективного поиска ближайших соседей в задачах машинного обучения. Она используется для ускорения операций, связанных с поиском подобных объектов на основе их эмбеддингов, например, в системе рекомендаций Циан.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries:  67%|██████▋   | 2/3 [00:09<00:04,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Как работает GPT?\n",
      "Документы: ### Как мы используем GPT\n",
      "GPT используется в нескольких автоматизированных пайплайнах GitLab CI для получения быстрой обратной связи о работе GitLab. CI-пайплайны эталонных архитектур работают с последним пре-релизом и, как правило, запускаются ежедневно или еженедельно. Сразу после тестирования мы анализируем результаты для поиска проблем. Все последние результаты мы публикуем в GPT wiki согласно нашему Transparency value.\n",
      "GPT также используется в пайплайне сравнительного тестирования, чтобы увидеть, как изменяется производительность GitLab от релиза к релизу. Эти результаты важны, так как показывают картину улучшения производительности. Результаты сравнения бенчмарков также доступны в GPT wiki.\n",
      " ---### Как вы можете использовать GPT\n",
      "Мы давно решили, что хотим следовать тем же принципам открытого исходного кода, как и для нашего основного продукта, поэтому при создании GPT мы ориентировались на всех пользователей, а не на то, чтобы сделать его исключительно внутренним продуктом. Поэтому мы не только позволяем использовать его другим, но и поощряем это! Это выгодно и нам и клиентам, так как мы получаем обратную связь с разных точек зрения, о которых мы и не думали. Некоторые примеры этого — улучшение руководств по рекомендуемым спецификациям основанных на пропускной способности, или улучшения в использовании GPT в автономном режиме для пользователей с частными облаками.\n",
      "Если вы хотите использовать GPT для себя, то лучше всего начать с документации. Как было отмечено, большая часть усилий по использованию GPT заключается в подготовке соответствующих окружений. В документации рассматривается как этот момент, так и непосредственное использование GPT.\n",
      "### GPT в действии\n",
      " ---### GPT в действии\n",
      "Наконец, после рассказов о GPT пришло время показать его в действии. Вот как выглядит запуск нагрузочного теста для List Group Projects API с 10k эталонной архитектурой:\n",
      "asciinema.org/a/O96Wc5fyxvLb1IDyviTwbujg8\n",
      "Для получения дополнительной информации о результатах смотрите документацию GPT.\n",
      "### Что дальше\n",
      "Наша цель — сделать GitLab, c точки зрения производительности, лучшим в своем классе. И мы только в начале этого пути. Мы рады тому, что можем улучшить качество обслуживания клиентов, предоставив им дополнительные инструменты.\n",
      "Некоторые наши планы на будущие релизы включают в себя расширение тестового покрытия функциональности GitLab, точек входа (API, Web, Git), расширение работы над эталонными архитектурами, тестовыми данными и шаблонами поведения пользователей, чтобы они были более репрезентативными и реалистичными.\n",
      "Поделитесь своими отзывами и/или предложениями по GPT в репозитории проекта GPT! Мы будем рады вашим идеям и предложениям.\n",
      "* * *\n",
      "Ansible: Быстрый старт.\n",
      "* * *\n",
      " ---### Что такое GitLab Performance tool (GPT)?\n",
      "GPT может использоваться для запуска различных нагрузочных тестов для бенчмарка GitLab. Все что требуется, это узнать, какую пропускную способность может выдержать тестируемая среда (в виде запросов в секунду), и обеспечить подготовку тестовых данных.\n",
      "GPT разработан на базе одного из ведущих инструментов для нагрузочного тестирования — k6. Вот некоторые из возможностей GPT:\n",
      "   Большой набор тестов из коробки, охватывающий различные конечные точки GitLab, с возможностью добавления своих тестов. Описание готовых тестов смотрите в документации, там часто добавляются новые тесты.\n",
      "   Параметры для запуска тестов, такие как необходимые данные для окружения GitLab или используемая пропускная способности.\n",
      "   Последовательный запуск тестов с выбором запускаемых тестов.\n",
      "   Расширенная отчетность и логирование.\n",
      " ---Языковая модель GPT-3 широко известна как инструмент для решения продвинутых задач написания текстов. Но есть одна новая возможность GPT-3, о которой не особенно много говорят. Она заключается в том, что OpenAI позволяет осуществлять тонкую настройку GPT-3 на данных, предоставленных пользователем. Если я передам GPT-3 большой набор данных, состоящий из хороших заголовков, можно ли будет использовать «подстроенную» модель для того, чтобы узнать о том, хорош или нет заголовок некоего поста из моего блога? Попытаемся найти ответ на этот вопрос.\n",
      "### Сбор данных о хороших постах с Hacker News\n",
      "Код и инструменты, использованные в этом материале, можно найти здесь.\n",
      "Ответ: GPT работает как языковая модель на основе нейронных сетей, разработанная OpenAI для генерации текста. Она может быть тонко настроена на конкретные задачи с использованием данных пользователя, что позволяет адаптировать её к различным приложениям, включая оценку качества заголовков. Однако, предоставленный контекст говорит о GPT, используемой для нагрузочных тестов и бенчмаркинга GitLab, а не для задач обработки текста или настройки модели под пользовательские данные. Поэтому, если речь идет о языковой модели GPT-3, она может быть тонко настроена на пользовательских данных, но в контексте нагрузочных тестов GitLab это не применимо.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 3/3 [00:13<00:00,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Что такое векторные базы данных?\n",
      "Документы: . Зачем это в государственнной базе данных?»\n",
      " ---В этой статье мы рассмотрим системы управления базами данных, а также узнаем, что же представляют собой реляционные и нереляционные базы и в чём заключаются их особенности.\n",
      "Ниже мы собрали список\n",
      "основных пунктов, чтобы вам было проще ориентироваться по статье:\n",
      "   Программное обеспечение для работы с современными базами данных\n",
      "   Основные функции программного обеспечения баз данных\n",
      "   Преимущества и недостатки СУБД\n",
      "   Реляционные базы данных\n",
      "   Нереляционные базы данных\n",
      "   Как выбрать тип базы?\n",
      "## Программное обеспечение для работы с современными базами данных\n",
      " ---\\- Структуры данных и тип данных что есть что?\n",
      "Структура данных \\- это контейнер, который хранит данные в определенном макете. Основные структуры данных: массивы, стеки, очереди, связные списки, графы, деревья, префиксные деревья, хэш-таблицы;\n",
      "Каждая переменная имеет свой тип, это определяет какие операции над ней можно производить, сколько байт она занимает в памяти, какие значения может иметь данная переменная. Различают следующие типы: целочисленные, с плавающей точкой, логический, символьный, специальные;\n",
      "C++ содержит очень гибкую систему для разработки, имеет множество инструментов и подходов к реализации приложений и программных решений, для новичка он может показаться немного трудным для освоения и потребовать дополнительных временных затрат и освоения кодовой базы\n",
      "\\- Указатели в С++, что это и какие бывают?;\n",
      " ---Необходимость рассмотрения ортонормированных базисов вызвана потребностями использования быстрых преобразований как одно –, так и многомерных функций. Задачи такой обработки возникают при исследовании кодов, кодирующих информационные сообщения в сетях связи различного назначения, при исследовании изображений, получаемых\n",
      "посредством автоматических и автоматизированных устройств, в ряде других областей, использующих цифровые представления информации.\n",
      "Определение. Совокупность n линейно независимых векторов n-мерного векторного\n",
      "пространства V называется его базисом.\n",
      "Теорема. Каждый вектор х линейного n-мерного векторного пространства V можно представить, притом единственным образом, в виде линейной комбинации векторов базиса. Векторное пространство V над полем F обладает следующими свойствами:\n",
      " ---. Естественным способом решения данной проблемы является специальная организация данных в базе (диаграмма Вороного, K-d-дерево и др.) плюс индексирование, хеширование и пр., позволяющие кардинально ускорить поиск. Конкретных реализаций указанных подходов существует огромное множество. Однако, все они позволяют находить ближайшего соседа либо приблизительно, либо с выделением больших объемов памяти на индексную информацию и большими вычислительными затратами на переиндексацию базы данных.\n",
      "Ответ: Векторные базы данных — это тип нереляционных баз данных, которые используют векторное представление для хранения и обработки данных, особенно полезны для задач машинного обучения и анализа больших объемов данных с высокой dimensionalностью. Они позволяют эффективно выполнять операции поиска ближайших соседей и кластеризации, что делает их подходящими для приложений в области компьютерного зрения, обработки естественного языка и рекомендательных систем.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "def generate_answer(query, retriever):\n",
    "    # Получение релевантных документов\n",
    "    relevant_docs = retriever.get_relevant_documents(query)\n",
    "    context = \"\\n ---\".join([doc.page_content for doc in relevant_docs])\n",
    "\n",
    "    # Генерация текста через Ollama\n",
    "    response = chain.invoke({\n",
    "        \"context\" : context,\n",
    "        \"question\" : query\n",
    "    })\n",
    "    return context, response\n",
    "\n",
    "# Запросы для генерации\n",
    "queries = [\"Что такое FAISS?\", \"Как работает GPT?\", \"Что такое векторные базы данных?\"]\n",
    "\n",
    "for query in tqdm(queries, desc=\"Processing queries\"):\n",
    "    context, answer = generate_answer(query, retriever)\n",
    "    print(f\"Вопрос: {query}\")\n",
    "    print(f\"Документы: {context}\")\n",
    "    print(f\"Ответ: {answer}\\n\")\n",
    "    print(f\"\\n\"*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".habr_rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
